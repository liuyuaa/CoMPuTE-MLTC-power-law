{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d92ee51-9196-4ee1-b9b7-f218d187e0ad",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70451d0c-b4bf-4566-a25c-42cd78b42839",
   "metadata": {},
   "source": [
    "## 0. Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d9764-f1a1-41ee-a3e3-73ba3ed252c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import patches\n",
    "from lifelines import KaplanMeierFitter\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from lifelines import CoxPHFitter\n",
    "from numpy import trapz\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f95c50-c562-49e5-abc5-99c0a7bef3c1",
   "metadata": {},
   "source": [
    "## 1. Mean Cumulative Count Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79574a31-9a26-4d4e-9718-f9e006f3d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "COND_LIST = ['Anx','Dep','SMI','Ast','COPD','Diab','Hyp','CHD','StroTIA','AF','HF','PAD','CKD','Dem','Park','Ost','RA','Can']\n",
    "AGE_BANDS = [[20,29],[30,39],[40,49],[50,59],[60,69],[70,79]]\n",
    "\n",
    "# ---------------- Core MCC on grid ----------------\n",
    "def compute_mcc_curve_yearscale(events_times, enter_age, exit_age, t_grid):\n",
    "    events_times = np.asarray(events_times, float)\n",
    "    enter_age = np.asarray(enter_age, float)\n",
    "    exit_age  = np.asarray(exit_age,  float)\n",
    "    t_grid    = np.asarray(t_grid,    float)\n",
    "\n",
    "    if events_times.size == 0:\n",
    "        return pd.DataFrame({\"t\": t_grid, \"mcc\": np.zeros_like(t_grid, float)})\n",
    "\n",
    "    dj_series = pd.Series(events_times).value_counts().sort_index()\n",
    "    ev_times = dj_series.index.values.astype(float)\n",
    "    dj = dj_series.values.astype(float)\n",
    "\n",
    "    enter_sorted = np.sort(enter_age)\n",
    "    exit_sorted  = np.sort(exit_age)\n",
    "    entered_before = np.searchsorted(enter_sorted, ev_times, side=\"right\")\n",
    "    exited_before  = np.searchsorted(exit_sorted,  ev_times, side=\"left\")\n",
    "    Yj = entered_before - exited_before\n",
    "\n",
    "    inc = np.zeros_like(ev_times, float)\n",
    "    valid = Yj > 0\n",
    "    inc[valid] = dj[valid] / Yj[valid]\n",
    "\n",
    "    mcc_at_ev = np.cumsum(inc)\n",
    "    idx = np.searchsorted(ev_times, t_grid, side=\"right\") - 1\n",
    "    mcc_grid = np.where(idx >= 0, mcc_at_ev[np.clip(idx, 0, len(mcc_at_ev)-1)], 0.0)\n",
    "\n",
    "    return pd.DataFrame({\"t\": t_grid, \"mcc\": mcc_grid})\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def assign_age_band(df, bands, index_age_col=\"1st_age\", band_label=\"1st_age_band\"):\n",
    "    def as_band(a):\n",
    "        if pd.isna(a): return np.nan\n",
    "        for (lo, hi) in bands:\n",
    "            if lo <= a <= hi: return (lo, hi)\n",
    "        return np.nan\n",
    "    out = df.copy()\n",
    "    out[band_label] = out[index_age_col].apply(as_band)\n",
    "    return out\n",
    "\n",
    "def riskset_over_grid(enter_age, exit_age, t_grid):\n",
    "    enter_sorted = np.sort(np.asarray(enter_age, float))\n",
    "    exit_sorted  = np.sort(np.asarray(exit_age,  float))\n",
    "    entered_before = np.searchsorted(enter_sorted, t_grid, side=\"right\")\n",
    "    exited_before  = np.searchsorted(exit_sorted,  t_grid, side=\"left\")\n",
    "    return entered_before - exited_before\n",
    "\n",
    "# ---------------- Landmark per person ----------------\n",
    "def landmark_per_person(sub_people, time_scale, index_age_col, band_col=\"1st_age_band\"):\n",
    "    return pd.Series(np.zeros(len(sub_people), dtype=float), index=sub_people.index)\n",
    "\n",
    "# ---------------- Events long table ----------------\n",
    "def build_events_long(df, cond_cols, id_col, time_scale, landmark_col_name, index_cond=None):\n",
    "    ev = df.melt(id_vars=[id_col, landmark_col_name], value_vars=cond_cols, var_name=\"condition\", value_name=\"onset_age\").dropna(subset=[\"onset_age\"]).copy()\n",
    "    if time_scale == \"attained_age\":\n",
    "        ev[\"event_time\"] = ev[\"onset_age\"].astype(float)\n",
    "    else:\n",
    "        raise ValueError(\"time_scale must be 'attained_age'.\")\n",
    "    return ev[[id_col, \"condition\", \"event_time\"]]\n",
    "\n",
    "# ---------------- One bootstrap replicate ----------------\n",
    "def bootstrap_replicate(args):\n",
    "    sub_people, cond_cols, t_grid, id_col, exit_col, time_scale, index_age_col, seed = args\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Resample IDs\n",
    "    ids = sub_people[id_col].unique()\n",
    "    samp_ids = rng.choice(ids, size=len(ids), replace=True)\n",
    "    samp = sub_people[sub_people[id_col].isin(samp_ids)].copy()\n",
    "\n",
    "    # Landmark\n",
    "    lm = landmark_per_person(samp, time_scale, index_age_col, \"1st_age_band\")\n",
    "    samp[\"__lm__\"] = lm.values\n",
    "\n",
    "    ev_b = build_events_long(samp, cond_cols, id_col=id_col, time_scale=time_scale, landmark_col_name=\"__lm__\", index_cond=sub_people['1st_cond'].values[0])\n",
    "    enter_b = np.zeros(len(samp))\n",
    "    exit_b = samp[exit_col].astype(float).values\n",
    "\n",
    "    return compute_mcc_curve_yearscale(ev_b[\"event_time\"].values, enter_b, exit_b, t_grid)[\"mcc\"].values\n",
    "\n",
    "# ---------------- MCC for one stratum with CI ----------------\n",
    "def mcc_for_stratum(sub_people, cond_cols, t_grid, id_col, exit_col, time_scale, index_age_col, min_alive=1000, n_boot=100, n_jobs=None):\n",
    "    lm = landmark_per_person(sub_people, time_scale, index_age_col, \"1st_age_band\")\n",
    "    tmp = sub_people.copy()\n",
    "    tmp[\"__lm__\"] = lm.values\n",
    "\n",
    "    ev_long = build_events_long(tmp, cond_cols, id_col=id_col, time_scale=time_scale, landmark_col_name=\"__lm__\", index_cond=sub_people['1st_cond'].values[0])\n",
    "    enter = np.zeros(len(sub_people), dtype=float)\n",
    "    exit_ = sub_people[exit_col].astype(float).values\n",
    "\n",
    "    # Truncate where Y > min_alive\n",
    "    Y = riskset_over_grid(enter, exit_, t_grid)\n",
    "    valid_idx = np.where(Y >= min_alive)[0]\n",
    "    if valid_idx.size == 0:\n",
    "        return None\n",
    "    tau_star = t_grid[valid_idx[-1]]\n",
    "    grid_trunc = t_grid[t_grid <= tau_star]\n",
    "\n",
    "    point_df = compute_mcc_curve_yearscale(ev_long[\"event_time\"].values, enter, exit_, grid_trunc)\n",
    "    point = point_df[\"mcc\"].values\n",
    "\n",
    "    # Bootstrap with multiprocessing\n",
    "    if n_boot > 0:\n",
    "        seeds = np.random.SeedSequence().spawn(n_boot)\n",
    "        args = [(sub_people, cond_cols, grid_trunc, id_col, exit_col, time_scale, index_age_col, int(s.generate_state(1)[0])) for s in seeds]\n",
    "        n_jobs = n_jobs or cpu_count()\n",
    "        with Pool(processes=n_jobs) as pool:\n",
    "            B = list(tqdm(pool.imap(bootstrap_replicate, args), total=n_boot, desc=\"Bootstrapping\"))\n",
    "        B = np.vstack(B)\n",
    "        lo = np.percentile(B, 2.5, axis=0)\n",
    "        hi = np.percentile(B, 97.5, axis=0)\n",
    "    else:\n",
    "        lo = np.full_like(point, np.nan)\n",
    "        hi = np.full_like(point, np.nan)\n",
    "    t = grid_trunc\n",
    "    return pd.DataFrame({\"t\": t, \"mcc\": point, \"mcc_lo\": lo, \"mcc_hi\": hi})\n",
    "\n",
    "# ---------------- Loop over strata ----------------\n",
    "def mcc_by_strata(df, cond_cols, t_grid, strata, id_col, exit_col, time_scale, index_age_col, min_alive=1000, n_boot=100, n_jobs=None):\n",
    "    out_rows = []\n",
    "    for keys in strata:\n",
    "        for key_vals, sub in tqdm(df.groupby(list(keys), dropna=False, sort=True)):\n",
    "            print(key_vals, sub.shape[0])\n",
    "            if not isinstance(key_vals, tuple):\n",
    "                key_vals = (key_vals,)\n",
    "            res = mcc_for_stratum(\n",
    "                sub_people=sub, cond_cols=cond_cols, t_grid=t_grid,\n",
    "                id_col=id_col, exit_col=exit_col,\n",
    "                time_scale=time_scale, index_age_col=index_age_col,\n",
    "                min_alive=min_alive, n_boot=n_boot, n_jobs=n_jobs\n",
    "            )\n",
    "            if res is None: \n",
    "                continue\n",
    "            for k, v in zip(keys, key_vals):\n",
    "                res[k] = str(v) if isinstance(v, (tuple, list)) else v\n",
    "            out_rows.append(res)\n",
    "    return pd.concat(out_rows, axis=0, ignore_index=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"MCC with CI (multiprocessing, landmark-corrected)\")\n",
    "    parser.add_argument(\"--input\",  default=\"./data/df_patient_20_80.csv\", help='Input file path')\n",
    "    parser.add_argument(\"--output\", default=\"./results/\", help='Output directory path')\n",
    "    parser.add_argument(\"--id_col\", default=\"patid\", help='Patient ID column name')\n",
    "    parser.add_argument(\"--index_age_col\", default=\"1st_age\", help='Index age column name')\n",
    "    parser.add_argument(\"--time_scale\", default=\"attained_age\", help='Time scale for analysis')\n",
    "    parser.add_argument(\"--min_alive\", type=int, default=1000, help='Minimum number of alive people for bootstrap')\n",
    "    parser.add_argument(\"--n_boot\", type=int, default=100, help='Number of bootstrap replicates')\n",
    "    parser.add_argument(\"--max_t\", type=int, default=100, help='Maximum age for analysis')\n",
    "    parser.add_argument(\"--n_jobs\", type=int, default=None, help=\"Processes for multiprocessing (default: all cores)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    df = pd.read_csv(args.input)\n",
    "    cond_cols = COND_LIST\n",
    "    df.loc[:, cond_cols] = (df[cond_cols].apply(pd.to_datetime, errors=\"coerce\").apply(lambda x: x.dt.year).sub(df[\"yob\"], axis=0))  # Convert condition date to age at event\n",
    "\n",
    "    df_ext = assign_age_band(df, AGE_BANDS, index_age_col=args.index_age_col, band_label=\"1st_age_band\") # Determine the index age band of each patient\n",
    "    t_grid = np.arange(0, args.max_t + 1, dtype=float)\n",
    "    strata = [(\"gender\",\"1st_cond\",\"1st_age_band\")]\n",
    "    df_ext = df_ext[df_ext['1st_cond']!='Health'] # Remove healthy people by end of 2019\n",
    "    df_mcc = mcc_by_strata(\n",
    "        df=df_ext, cond_cols=cond_cols, t_grid=t_grid, strata=strata,\n",
    "        id_col=args.id_col, exit_col=\"exit_age\",\n",
    "        time_scale=args.time_scale, index_age_col=args.index_age_col,\n",
    "        min_alive=args.min_alive, n_boot=args.n_boot, n_jobs=args.n_jobs\n",
    "    ) # Calculate MCC and confidence interval\n",
    "    df_mcc.to_csv(args.output+'mcc_'+args.time_scale+'_ci.csv', index=False)\n",
    "    print(f\"Saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635e546-54a8-405a-803d-90489896b7da",
   "metadata": {},
   "source": [
    "## 2. Power-Law Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8f41f-101d-4a1e-bb71-a20dc6312b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_law(t, alpha, beta):\n",
    "    return alpha * (t) ** beta\n",
    "    \n",
    "# --------------------------\n",
    "# f1: Fit power law for one stratum (with bootstrap)\n",
    "# --------------------------\n",
    "def fit_power_law_stratum(df_stratum, band_str, n_boot=100, least_fit_pts=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Fit f(t) = alpha * (t)^beta for one stratum.\n",
    "    Adds bootstrap confidence intervals for alpha, beta.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    band = eval(band_str)\n",
    "    t0 = float(band[1])\n",
    "    # Subset points AFTER band upper bound\n",
    "    df_fit = df_stratum[df_stratum[\"t\"] > t0].copy()\n",
    "    if df_fit.empty or len(df_fit) < least_fit_pts:\n",
    "        return None\n",
    "    x = df_fit[\"t\"].values - df_fit[\"t\"].values[0] \n",
    "    y = df_fit[\"mcc\"].values - df_fit[\"mcc\"].values[0]\n",
    "    x = x[1:]\n",
    "    y = y[1:]\n",
    "    # Initial guesses\n",
    "    p0 = [y[0], 1.25]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(lambda t, alpha, beta: power_law(t, alpha, beta), x, y, p0=p0, maxfev=20000)\n",
    "        alpha, beta = popt\n",
    "        perr = np.sqrt(np.diag(pcov))  # standard errors\n",
    "    except RuntimeError:\n",
    "        return None\n",
    "    # Predictions and error metrics\n",
    "    y_pred = power_law(x, alpha, beta)\n",
    "    metrics = evaluate_fit(y, y_pred)\n",
    "    # --------------------------\n",
    "    # Bootstrap for CI\n",
    "    # --------------------------\n",
    "    alpha_boot, beta_boot = [], []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(len(x), size=len(x), replace=True)\n",
    "        xb, yb = x[idx], y[idx]\n",
    "        try:\n",
    "            popt_b, _ = curve_fit(lambda t, a, b: power_law(t, a, b), xb, yb, p0=[alpha, beta], maxfev=10000)\n",
    "            alpha_boot.append(popt_b[0])\n",
    "            beta_boot.append(popt_b[1])\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "    if alpha_boot and beta_boot:\n",
    "        alpha_ci = (np.percentile(alpha_boot, 2.5), np.percentile(alpha_boot, 97.5))\n",
    "        beta_ci  = (np.percentile(beta_boot, 2.5), np.percentile(beta_boot, 97.5))\n",
    "    else:\n",
    "        alpha_ci = (np.nan, np.nan)\n",
    "        beta_ci  = (np.nan, np.nan)\n",
    "    return {\"alpha\": alpha, \"beta\": beta, \"alpha_se\": perr[0], \"beta_se\": perr[1], \"alpha_ci_low\": alpha_ci[0], \"alpha_ci_high\": alpha_ci[1],\n",
    "            \"beta_ci_low\": beta_ci[0], \"beta_ci_high\": beta_ci[1], \"n_points\": len(x), **metrics}\n",
    "\n",
    "# --------------------------\n",
    "# f2: Error metrics\n",
    "# --------------------------\n",
    "def evaluate_fit(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "\n",
    "# --------------------------\n",
    "# Fit across all strata\n",
    "# --------------------------\n",
    "def fit_all_strata(df_plot, n_boot=100, imd=None, least_fit_pts=5):\n",
    "    results = []\n",
    "    if imd is not None:\n",
    "        for (g, cond, band, imd_i), sub in df_plot.groupby([\"gender\",\"1st_cond\",\"1st_age_band\"] + ['imd']):\n",
    "            if band in age_bands:\n",
    "                res = fit_power_law_stratum(sub, band, n_boot, least_fit_pts)\n",
    "                if res is not None:\n",
    "                    res[\"gender\"] = g\n",
    "                    res[\"condition\"] = cond\n",
    "                    res[\"band\"] = band\n",
    "                    res['imd'] = imd_i\n",
    "                    results.append(res)\n",
    "        return pd.DataFrame(results)\n",
    "    else:\n",
    "        for (g, cond, band), sub in df_plot.groupby([\"gender\",\"1st_cond\",\"1st_age_band\"]):\n",
    "            res = fit_power_law_stratum(sub, band, n_boot, least_fit_pts)\n",
    "            if res is not None and band in age_bands:\n",
    "                res[\"gender\"] = g\n",
    "                res[\"condition\"] = cond\n",
    "                res[\"band\"] = band\n",
    "                results.append(res)\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "dir_out = './results/'\n",
    "time_scale = 'attained_age'\n",
    "n_plot_points = 5\n",
    "df_plot = pd.read_csv(dir_out+'mcc_'+args.time_scale+'_ci.csv')\n",
    "df_plot = df_plot[df_plot['1st_cond'].isin(cond_date_list)]\n",
    "df_results = fit_all_strata(df_plot, n_boot=100, imd=None, least_fit_pts=n_plot_points)\n",
    "df_results = df_results[['alpha', 'alpha_ci_low', 'alpha_ci_high', 'beta', 'beta_ci_low', 'beta_ci_high', 'rmse', 'mae', 'r2', 'gender', 'condition', 'band']]\n",
    "df_results = df_results.rename(columns={'condition': '1st_cond', 'band': '1st_age_band'})\n",
    "df_results.to_csv(dir_out+'mcc_fit_power_law.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd6c413-efc7-48a3-b1f3-f6c222c358b9",
   "metadata": {},
   "source": [
    "## 3. Analysis of Socioeconomic Deprivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004f5f4-dde0-43f6-9fd8-929c0693cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import norm\n",
    "\n",
    "df = pd.read_csv('./results/mcc_fit_power_law_imd.csv')\n",
    "pairs = []\n",
    "cond_sel_list = ['Anx', 'Dep', 'Ast', 'Diab', 'Hyp', 'CHD', 'Can']\n",
    "age_bands = ['(20, 29)', '(30, 39)', '(40, 49)', '(50, 59)', '(60, 69)', '(70, 79)']\n",
    "for g in ['M', 'F']:\n",
    "    for metric_i in ['alpha', 'beta']:\n",
    "        for cond_i in cond_sel_list:\n",
    "            for ag_i in age_bands:\n",
    "                df_beta = df[(df['gender']==g) & (df['condition']==cond_i) & (df['band']==ag_i)]\n",
    "                if 1 in df_beta['imd'].unique() and 5 in df_beta['imd'].unique():\n",
    "                    for i, j in combinations(sorted([1, 5]), 2):\n",
    "                        bi, bj = df_beta.loc[df_beta['imd']==i, metric_i].values[0], df_beta.loc[df_beta['imd']==j, metric_i].values[0]\n",
    "                        sei, sej = df_beta.loc[df_beta['imd']==i, metric_i+'_se'].values[0], df_beta.loc[df_beta['imd']==j, metric_i+'_se'].values[0]\n",
    "                        z = (bi - bj) / np.sqrt(sei**2 + sej**2)\n",
    "                        p = 2 * (1 - norm.cdf(abs(z)))\n",
    "                        pairs.append((g, metric_i, cond_i, ag_i, i, j, bi, bj, z, p))\n",
    "df_pval = pd.DataFrame(pairs, columns=['gender', 'metric', 'cond', 'age_band', 'IMD_i','IMD_j','v_i','v_j','z','p'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
