{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d92ee51-9196-4ee1-b9b7-f218d187e0ad",
   "metadata": {},
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70451d0c-b4bf-4566-a25c-42cd78b42839",
   "metadata": {},
   "source": [
    "## 0. Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d9764-f1a1-41ee-a3e3-73ba3ed252c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import patches\n",
    "from lifelines import KaplanMeierFitter\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from lifelines import CoxPHFitter\n",
    "from numpy import trapz\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2064c52-919a-4652-b451-ebfecfc89e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79574a31-9a26-4d4e-9718-f9e006f3d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple, Optional\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "# ---------------- Configuration ----------------\n",
    "COND_LIST = ['Anx','Dep','SMI','Ast','COPD','Diab','Hyp','CHD','StroTIA','AF','HF','PAD','CKD','Dem','Park','Ost','RA','Can']\n",
    "AGE_BANDS = [[20,29],[30,39],[40,49],[50,59],[60,69],[70,79]]\n",
    "\n",
    "# ---------------- Core MCC on grid ----------------\n",
    "def compute_mcc_curve_yearscale(events_times, enter_age, exit_age, t_grid):\n",
    "    events_times = np.asarray(events_times, float)\n",
    "    enter_age = np.asarray(enter_age, float)\n",
    "    exit_age  = np.asarray(exit_age,  float)\n",
    "    t_grid    = np.asarray(t_grid,    float)\n",
    "\n",
    "    if events_times.size == 0:\n",
    "        return pd.DataFrame({\"t\": t_grid, \"mcc\": np.zeros_like(t_grid, float)})\n",
    "\n",
    "    dj_series = pd.Series(events_times).value_counts().sort_index()\n",
    "    ev_times = dj_series.index.values.astype(float)\n",
    "    dj = dj_series.values.astype(float)\n",
    "\n",
    "    enter_sorted = np.sort(enter_age)\n",
    "    exit_sorted  = np.sort(exit_age)\n",
    "    entered_before = np.searchsorted(enter_sorted, ev_times, side=\"right\")\n",
    "    exited_before  = np.searchsorted(exit_sorted,  ev_times, side=\"left\")\n",
    "    Yj = entered_before - exited_before\n",
    "\n",
    "    inc = np.zeros_like(ev_times, float)\n",
    "    valid = Yj > 0\n",
    "    inc[valid] = dj[valid] / Yj[valid]\n",
    "\n",
    "    mcc_at_ev = np.cumsum(inc)\n",
    "    idx = np.searchsorted(ev_times, t_grid, side=\"right\") - 1\n",
    "    mcc_grid = np.where(idx >= 0, mcc_at_ev[np.clip(idx, 0, len(mcc_at_ev)-1)], 0.0)\n",
    "\n",
    "    return pd.DataFrame({\"t\": t_grid, \"mcc\": mcc_grid})\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "def assign_age_band(df, bands, index_age_col=\"1st_age\", band_label=\"1st_age_band\"):\n",
    "    def as_band(a):\n",
    "        if pd.isna(a): return np.nan\n",
    "        for (lo, hi) in bands:\n",
    "            if lo <= a <= hi: return (lo, hi)\n",
    "        return np.nan\n",
    "    out = df.copy()\n",
    "    out[band_label] = out[index_age_col].apply(as_band)\n",
    "    return out\n",
    "\n",
    "def riskset_over_grid(enter_age, exit_age, t_grid):\n",
    "    enter_sorted = np.sort(np.asarray(enter_age, float))\n",
    "    exit_sorted  = np.sort(np.asarray(exit_age,  float))\n",
    "    entered_before = np.searchsorted(enter_sorted, t_grid, side=\"right\")\n",
    "    exited_before  = np.searchsorted(exit_sorted,  t_grid, side=\"left\")\n",
    "    return entered_before - exited_before\n",
    "\n",
    "# ---------------- Landmark per person ----------------\n",
    "def landmark_per_person(sub_people, time_scale, index_age_col, band_col=\"1st_age_band\"):\n",
    "    return pd.Series(np.zeros(len(sub_people), dtype=float), index=sub_people.index)\n",
    "\n",
    "# ---------------- Events long table ----------------\n",
    "def build_events_long(df, cond_cols, id_col, time_scale, landmark_col_name, index_cond=None):\n",
    "    ev = df.melt(id_vars=[id_col, landmark_col_name], value_vars=cond_cols, var_name=\"condition\", value_name=\"onset_age\").dropna(subset=[\"onset_age\"]).copy()\n",
    "    if time_scale == \"attained_age\":\n",
    "        ev[\"event_time\"] = ev[\"onset_age\"].astype(float)\n",
    "    else:\n",
    "        raise ValueError(\"time_scale must be 'attained_age'.\")\n",
    "    return ev[[id_col, \"condition\", \"event_time\"]]\n",
    "\n",
    "# ---------------- One bootstrap replicate ----------------\n",
    "def bootstrap_replicate(args):\n",
    "    sub_people, cond_cols, t_grid, id_col, exit_col, time_scale, index_age_col, seed = args\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # Resample IDs\n",
    "    ids = sub_people[id_col].unique()\n",
    "    samp_ids = rng.choice(ids, size=len(ids), replace=True)\n",
    "    samp = sub_people[sub_people[id_col].isin(samp_ids)].copy()\n",
    "\n",
    "    # Landmark\n",
    "    lm = landmark_per_person(samp, time_scale, index_age_col, \"1st_age_band\")\n",
    "    samp[\"__lm__\"] = lm.values\n",
    "\n",
    "    ev_b = build_events_long(samp, cond_cols, id_col=id_col, time_scale=time_scale, landmark_col_name=\"__lm__\", index_cond=sub_people['1st_cond'].values[0])\n",
    "    enter_b = np.zeros(len(samp))\n",
    "    exit_b = samp[exit_col].astype(float).values\n",
    "\n",
    "    return compute_mcc_curve_yearscale(ev_b[\"event_time\"].values, enter_b, exit_b, t_grid)[\"mcc\"].values\n",
    "\n",
    "# ---------------- MCC for one stratum with CI ----------------\n",
    "def mcc_for_stratum(sub_people, cond_cols, t_grid, id_col, exit_col, time_scale, index_age_col, min_alive=1000, n_boot=100, n_jobs=None):\n",
    "    lm = landmark_per_person(sub_people, time_scale, index_age_col, \"1st_age_band\")\n",
    "    tmp = sub_people.copy()\n",
    "    tmp[\"__lm__\"] = lm.values\n",
    "\n",
    "    ev_long = build_events_long(tmp, cond_cols, id_col=id_col, time_scale=time_scale, landmark_col_name=\"__lm__\", index_cond=sub_people['1st_cond'].values[0])\n",
    "    enter = np.zeros(len(sub_people), dtype=float)\n",
    "    exit_ = sub_people[exit_col].astype(float).values\n",
    "\n",
    "    # Truncate where Y > min_alive\n",
    "    Y = riskset_over_grid(enter, exit_, t_grid)\n",
    "    valid_idx = np.where(Y >= min_alive)[0]\n",
    "    if valid_idx.size == 0:\n",
    "        return None\n",
    "    tau_star = t_grid[valid_idx[-1]]\n",
    "    grid_trunc = t_grid[t_grid <= tau_star]\n",
    "\n",
    "    point_df = compute_mcc_curve_yearscale(ev_long[\"event_time\"].values, enter, exit_, grid_trunc)\n",
    "    point = point_df[\"mcc\"].values\n",
    "\n",
    "    # Bootstrap with multiprocessing\n",
    "    if n_boot > 0:\n",
    "        seeds = np.random.SeedSequence().spawn(n_boot)\n",
    "        args = [(sub_people, cond_cols, grid_trunc, id_col, exit_col, time_scale, index_age_col, int(s.generate_state(1)[0])) for s in seeds]\n",
    "        n_jobs = n_jobs or cpu_count()\n",
    "        with Pool(processes=n_jobs) as pool:\n",
    "            B = list(tqdm(pool.imap(bootstrap_replicate, args), total=n_boot, desc=\"Bootstrapping\"))\n",
    "        B = np.vstack(B)\n",
    "        lo = np.percentile(B, 2.5, axis=0)\n",
    "        hi = np.percentile(B, 97.5, axis=0)\n",
    "    else:\n",
    "        lo = np.full_like(point, np.nan)\n",
    "        hi = np.full_like(point, np.nan)\n",
    "    t = grid_trunc\n",
    "    return pd.DataFrame({\"t\": t, \"mcc\": point, \"mcc_lo\": lo, \"mcc_hi\": hi})\n",
    "\n",
    "# ---------------- Loop over strata ----------------\n",
    "def mcc_by_strata(df, cond_cols, t_grid, strata, id_col, exit_col, time_scale, index_age_col, min_alive=1000, n_boot=100, n_jobs=None):\n",
    "    out_rows = []\n",
    "    for keys in strata:\n",
    "        for key_vals, sub in tqdm(df.groupby(list(keys), dropna=False, sort=True)):\n",
    "            print(key_vals, sub.shape[0])\n",
    "            if not isinstance(key_vals, tuple):\n",
    "                key_vals = (key_vals,)\n",
    "            res = mcc_for_stratum(\n",
    "                sub_people=sub, cond_cols=cond_cols, t_grid=t_grid,\n",
    "                id_col=id_col, exit_col=exit_col,\n",
    "                time_scale=time_scale, index_age_col=index_age_col,\n",
    "                min_alive=min_alive, n_boot=n_boot, n_jobs=n_jobs\n",
    "            )\n",
    "            if res is None: \n",
    "                continue\n",
    "            for k, v in zip(keys, key_vals):\n",
    "                res[k] = str(v) if isinstance(v, (tuple, list)) else v\n",
    "            out_rows.append(res)\n",
    "    return pd.concat(out_rows, axis=0, ignore_index=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"MCC with CI (multiprocessing, landmark-corrected)\")\n",
    "    parser.add_argument(\"--input\",  default=\"./data/df_patient_20_80.csv\", help='Input file path')\n",
    "    parser.add_argument(\"--output\", default=\"./results/\", help='Output directory path')\n",
    "    parser.add_argument(\"--id_col\", default=\"patid\", help='Patient ID column name')\n",
    "    parser.add_argument(\"--index_age_col\", default=\"1st_age\", help='Index age column name')\n",
    "    parser.add_argument(\"--time_scale\", default=\"attained_age\", help='Time scale for analysis')\n",
    "    parser.add_argument(\"--min_alive\", type=int, default=1000, help='Minimum number of alive people for bootstrap')\n",
    "    parser.add_argument(\"--n_boot\", type=int, default=100, help='Number of bootstrap replicates')\n",
    "    parser.add_argument(\"--max_t\", type=int, default=100, help='Maximum age for analysis')\n",
    "    parser.add_argument(\"--n_jobs\", type=int, default=None, help=\"Processes for multiprocessing (default: all cores)\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    df = pd.read_csv(args.input)\n",
    "    cond_cols = COND_LIST\n",
    "    df.loc[:, cond_cols] = (df[cond_cols].apply(pd.to_datetime, errors=\"coerce\").apply(lambda x: x.dt.year).sub(df[\"yob\"], axis=0))  # Convert condition date to age at event\n",
    "\n",
    "    df_ext = assign_age_band(df, AGE_BANDS, index_age_col=args.index_age_col, band_label=\"1st_age_band\") # Determine the index age band of each patient\n",
    "    t_grid = np.arange(0, args.max_t + 1, dtype=float)\n",
    "    strata = [(\"gender\",\"1st_cond\",\"1st_age_band\")]\n",
    "    df_ext = df_ext[df_ext['1st_cond']!='Health'] # Remove healthy people by end of 2019\n",
    "    df_mcc = mcc_by_strata(\n",
    "        df=df_ext, cond_cols=cond_cols, t_grid=t_grid, strata=strata,\n",
    "        id_col=args.id_col, exit_col=\"exit_age\",\n",
    "        time_scale=args.time_scale, index_age_col=args.index_age_col,\n",
    "        min_alive=args.min_alive, n_boot=args.n_boot, n_jobs=args.n_jobs\n",
    "    ) # Calculate MCC and confidence interval\n",
    "    df_mcc.to_csv(args.output+'mcc_'+args.time_scale+'_ci.csv', index=False)\n",
    "    print(f\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455e218-95e9-45ef-9612-c7334e58dce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b8f41f-101d-4a1e-bb71-a20dc6312b70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
